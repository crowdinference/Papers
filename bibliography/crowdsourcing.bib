@article{raykar2010learning,
  title={Learning from crowds},
  author={Raykar, Vikas C and Yu, Shipeng and Zhao, Linda H and Valadez, Gerardo Hermosillo and Florin, Charles and Bogoni, Luca and Moy, Linda},
  journal={Journal of Machine Learning Research},
  volume={11},
  number={Apr},
  pages={1297--1322},
  year={2010}
}
For many supervised learning tasks it may be infeasible (or very expensive) to obtain objective and reliable labels. Instead, we can collect subjective (possibly noisy) labels from multiple experts or annotators. In practice, there is a substantial amount of disagreement among the annotators, and hence it is of great practical interest to address conventional supervised learning problems in this scenario. In this paper we describe a probabilistic approach for supervised learning when we have multiple annotators providing (possibly noisy) labels but no absolute gold standard. The proposed algorithm evaluates the different experts and also gives an estimate of the actual hidden labels. Experimental results indicate that the proposed method is superior to the commonly used majority voting baseline.

@article{dawid1979maximum,
  title={Maximum likelihood estimation of observer error-rates using the EM algorithm},
  author={Dawid, Alexander Philip and Skene, Allan M},
  journal={Journal of the Royal Statistical Society: Series C (Applied Statistics)},
  volume={28},
  number={1},
  pages={20--28},
  year={1979},
  publisher={Wiley Online Library}
}
In compiling a patient record many facets are subject to errors of measurement. A model is presented which allows individual error‐rates to be estimated for polytomous facets even when the patient's “true” response is not available. The EM algorithm is shown to provide a slow but sure way of obtaining maximum likelihood estimates of the parameters of interest. Some preliminary experience is reported and the limitations of the method are described.